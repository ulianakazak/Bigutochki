{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import fbeta_score,make_scorer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import paired_distances\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('snli_1.0/snli_1.0_train.jsonl', lines = True)\n",
    "test = pd.read_json('snli_1.0/snli_1.0_test.jsonl', lines = True)\n",
    "val = pd.read_json('snli_1.0/snli_1.0_dev.jsonl', lines = True)\n",
    "full = {'train': train, 'val':val, 'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>captionID</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3416050480.jpg#4r1n</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>( ( A person ) ( ( is ( ( training ( his horse...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[contradiction]</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>3416050480.jpg#4r1c</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[entailment]</td>\n",
       "      <td>3416050480.jpg#4</td>\n",
       "      <td>entailment</td>\n",
       "      <td>3416050480.jpg#4r1e</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...</td>\n",
       "      <td>(ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[neutral]</td>\n",
       "      <td>2267923837.jpg#2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2267923837.jpg#2r1n</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
       "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>( They ( are ( smiling ( at ( their parents ) ...</td>\n",
       "      <td>(ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[entailment]</td>\n",
       "      <td>2267923837.jpg#2</td>\n",
       "      <td>entailment</td>\n",
       "      <td>2267923837.jpg#2r1e</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>( Children ( ( ( smiling and ) waving ) ( at c...</td>\n",
       "      <td>(ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>( There ( ( are children ) present ) )</td>\n",
       "      <td>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  annotator_labels         captionID     gold_label               pairID  \\\n",
       "0        [neutral]  3416050480.jpg#4        neutral  3416050480.jpg#4r1n   \n",
       "1  [contradiction]  3416050480.jpg#4  contradiction  3416050480.jpg#4r1c   \n",
       "2     [entailment]  3416050480.jpg#4     entailment  3416050480.jpg#4r1e   \n",
       "3        [neutral]  2267923837.jpg#2        neutral  2267923837.jpg#2r1n   \n",
       "4     [entailment]  2267923837.jpg#2     entailment  2267923837.jpg#2r1e   \n",
       "\n",
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                              sentence1_binary_parse  \\\n",
       "0  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "1  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "2  ( ( ( A person ) ( on ( a horse ) ) ) ( ( jump...   \n",
       "3  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
       "4  ( Children ( ( ( smiling and ) waving ) ( at c...   \n",
       "\n",
       "                                     sentence1_parse  \\\n",
       "0  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "1  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "2  (ROOT (S (NP (NP (DT A) (NN person)) (PP (IN o...   \n",
       "3  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
       "4  (ROOT (NP (S (NP (NNP Children)) (VP (VBG smil...   \n",
       "\n",
       "                                           sentence2  \\\n",
       "0  A person is training his horse for a competition.   \n",
       "1      A person is at a diner, ordering an omelette.   \n",
       "2                  A person is outdoors, on a horse.   \n",
       "3                  They are smiling at their parents   \n",
       "4                         There are children present   \n",
       "\n",
       "                              sentence2_binary_parse  \\\n",
       "0  ( ( A person ) ( ( is ( ( training ( his horse...   \n",
       "1  ( ( A person ) ( ( ( ( is ( at ( a diner ) ) )...   \n",
       "2  ( ( A person ) ( ( ( ( is outdoors ) , ) ( on ...   \n",
       "3  ( They ( are ( smiling ( at ( their parents ) ...   \n",
       "4             ( There ( ( are children ) present ) )   \n",
       "\n",
       "                                     sentence2_parse  \n",
       "0  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
       "1  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
       "2  (ROOT (S (NP (DT A) (NN person)) (VP (VBZ is) ...  \n",
       "3  (ROOT (S (NP (PRP They)) (VP (VBP are) (VP (VB...  \n",
       "4  (ROOT (S (NP (EX There)) (VP (VBP are) (NP (NN...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550152 entries, 0 to 550151\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   annotator_labels        550152 non-null  object\n",
      " 1   captionID               550152 non-null  object\n",
      " 2   gold_label              550152 non-null  object\n",
      " 3   pairID                  550152 non-null  object\n",
      " 4   sentence1               550152 non-null  object\n",
      " 5   sentence1_binary_parse  550152 non-null  object\n",
      " 6   sentence1_parse         550152 non-null  object\n",
      " 7   sentence2               550152 non-null  object\n",
      " 8   sentence2_binary_parse  550152 non-null  object\n",
      " 9   sentence2_parse         550152 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 42.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train gold_label\n",
      "-                   785\n",
      "contradiction    183187\n",
      "entailment       183416\n",
      "neutral          182764\n",
      "Name: gold_label, dtype: int64\n",
      "\n",
      "val gold_label\n",
      "-                 158\n",
      "contradiction    3278\n",
      "entailment       3329\n",
      "neutral          3235\n",
      "Name: gold_label, dtype: int64\n",
      "\n",
      "test gold_label\n",
      "-                 176\n",
      "contradiction    3237\n",
      "entailment       3368\n",
      "neutral          3219\n",
      "Name: gold_label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def label_distribution(data, frame):\n",
    "    print(frame, data.groupby('gold_label')['gold_label'].count())\n",
    "    print()\n",
    "    \n",
    "\n",
    "for frame in full:\n",
    "    label_distribution(full[frame], frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unsure_labels(data):\n",
    "    #удаляет объекты, у к-х лейбл '-' (т.е вид связи неопределён)\n",
    "    data = data.drop(index = data[data.gold_label == '-'].index)\n",
    "    return data\n",
    "\n",
    "\n",
    "for frame in full:\n",
    "    full[frame] = delete_unsure_labels(full[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full['train']\n",
    "val = full['val']\n",
    "test = full['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = train.sentence1 +\" \"+ train.sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A person on a horse jumps over a broken down airplane. A person is training his horse for a competition.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, sublinear_tf=False,\n",
       "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "tfidf = TfidfVectorizer(stop_words=stop)\n",
    "tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_distance(data):\n",
    "    # преобразует предложения и считает расстояния(евклидово, матхэт., косинусное) между преобразованными предложениями\n",
    "    data_sentence1 = tfidf.transform(data.sentence1)\n",
    "    data_sentence2 = tfidf.transform(data.sentence2)\n",
    "    difference = data_sentence1 - data_sentence2\n",
    "    \n",
    "    euclidean = paired_distances(data_sentence1, data_sentence2, metric='euclidean')\n",
    "    manhattan= paired_distances(data_sentence1, data_sentence2, metric='manhattan')\n",
    "    cosine = paired_distances(data_sentence1, data_sentence2, metric='cosine')\n",
    "\n",
    "    distances =  hstack((np.array([euclidean, manhattan, cosine]).T, difference))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  tfidf_distance(train)\n",
    "y_train = train.gold_label\n",
    "\n",
    "X_val = tfidf_distance(val)\n",
    "y_val = val.gold_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64774937, 0.64994823, 0.64645655])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=200, solver = 'saga')\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=3, average='weighted', labels=['contradiction', 'neutral', 'entailment'])\n",
    "cross_val_score(clf, X_train , y_train, cv=3, scoring= ftwo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=200,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3f2a7378745c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_val_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my_val_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "y_val_probas = clf.predict_proba(X_val)\n",
    "y_val_preds = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric(y_true, y_preds):\n",
    "    prfs = precision_recall_fscore_support(y_val, y_val_preds, beta=3, average=None, labels=['contradiction', 'neutral', 'entailment'])\n",
    "    matrix_report = pd.DataFrame(prfs, columns = ['contradiction', 'neutral', 'entailment'], index = ['precision', 'recall', 'fscore', 'support'])\n",
    "    matrix_report['Weighted*'] = 0.5 * matrix_report['contradiction'] +  0.25 * matrix_report['neutral'] +  0.25 * matrix_report['entailment']\n",
    "    matrix_report.drop(index = 'support', inplace = True)\n",
    "    print(matrix_report.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall    fscore\n",
      "contradiction   0.661084  0.662294  0.662173\n",
      "neutral         0.674443  0.607728  0.613800\n",
      "entailment      0.688169  0.753079  0.746042\n",
      "Weighted*       0.671195  0.671349  0.671047\n"
     ]
    }
   ],
   "source": [
    "print_metric(y_val,y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = np.where(y_val_probas[:, 0] > 0.3, 'contradiction', y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall    fscore\n",
      "contradiction   0.573234  0.774863  0.748534\n",
      "neutral         0.721377  0.498609  0.514497\n",
      "entailment      0.708976  0.676179  0.679322\n",
      "Weighted*       0.644205  0.681128  0.672722\n"
     ]
    }
   ],
   "source": [
    "print_metric(y_val,y_val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-ffef62eaa9d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgbc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=31).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall    fscore\n",
      "contradiction   0.629988  0.616534  0.617854\n",
      "neutral         0.587302  0.548995  0.552600\n",
      "entailment      0.643767  0.698108  0.692264\n",
      "Weighted*       0.622761  0.620043  0.620143\n"
     ]
    }
   ],
   "source": [
    "y_val_preds = gbc.predict(X_val)\n",
    "y_val_probas = gbc.predict_proba(X_val)\n",
    "#y_val_preds = np.where(y_val_probas[:, 0] > 0.3, 'contradiction', y_val_preds)\n",
    "print_metric(y_val,y_val_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall    fscore\n",
      "contradiction   0.629988  0.616534  0.617854\n",
      "neutral         0.587302  0.548995  0.552600\n",
      "entailment      0.643767  0.698108  0.692264\n",
      "Weighted*       0.622761  0.620043  0.620143\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall    fscore\n",
      "contradiction   0.670187  0.677547  0.676804\n",
      "neutral         0.614149  0.614529  0.614491\n",
      "entailment      0.708295  0.700210  0.701010\n",
      "Weighted*       0.665705  0.667458  0.667277\n"
     ]
    }
   ],
   "source": [
    "y_val_preds = xgb.predict(X_val)\n",
    "y_val_probas = xgb.predict_proba(X_val)\n",
    "print_metric(y_val,y_val_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
