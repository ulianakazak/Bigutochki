{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем csv с векторами предложений. Один файл - либо 1, либо 2 предложение одной из частей данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename):\n",
    "    with open(filename) as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        vectors = []\n",
    "        i = 0\n",
    "        for row in spamreader:\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            row = [float(el) for el in row[1:]]\n",
    "            vectors.append(row)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_link(response):\n",
    "    spamreader = csv.reader(response)\n",
    "    vectors = []\n",
    "    i = 0\n",
    "    for row in spamreader:\n",
    "        if i == 0:\n",
    "            i += 1\n",
    "            continue\n",
    "        row = [float(el) for el in row[1:]]\n",
    "        vectors.append(row)\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем расстояние между векторами предложений, здесь тоже просто вычитается один из другого, мб можно попробовать другие метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dist(file1, file2):\n",
    "    vectors_1 = read_csv(file1)\n",
    "    vectors_2 = read_csv(file2)\n",
    "    vectors_1 = np.array([np.array(vectors_1[i]) for i in range(len(vectors_1))])\n",
    "    vectors_2 = np.array([np.array(vectors_2[i]) for i in range(len(vectors_2))])\n",
    "    dist_1 = vectors_1 - vectors_2\n",
    "    return dist_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dist_link(file1, file2):\n",
    "    vectors_1 = read_csv_link(file1)\n",
    "    vectors_2 = read_csv_link(file2)\n",
    "    vectors_1 = np.array([np.array(vectors_1[i]) for i in range(len(vectors_1))])\n",
    "    vectors_2 = np.array([np.array(vectors_2[i]) for i in range(len(vectors_2))])\n",
    "    dist_1 = vectors_1 - vectors_2\n",
    "    return dist_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если есть файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = count_dist('train_1.csv', 'train_2.csv')\n",
    "X_val = count_dist('val_1.csv', 'val_2.csv')\n",
    "X_test = count_dist('test_1.csv', 'test_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачать с гита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_val_1_1 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/val_1_1.csv')\n",
    "response_val_2_1 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/val_2_1.csv')\n",
    "response_val_1_2 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/val_1_2.csv')\n",
    "response_val_2_2 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/val_2_2.csv')\n",
    "response_test_1_1 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/test_1_1.csv')\n",
    "response_test_2_1 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/test_2_1.csv')\n",
    "response_test_1_2 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/test_1_2.csv')\n",
    "response_test_2_2 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/test_2_2.csv')\n",
    "\n",
    "X_val_1 = count_dist_link(io.TextIOWrapper(response_val_1_1), io.TextIOWrapper(response_val_2_1))\n",
    "X_val_2 = count_dist_link(io.TextIOWrapper(response_val_1_2), io.TextIOWrapper(response_val_2_2))\n",
    "X_val = np.vstack((X_val_1, X_val_2))\n",
    "\n",
    "X_test_1 = count_dist_link(io.TextIOWrapper(response_test_1_1), io.TextIOWrapper(response_test_2_1))\n",
    "X_test_2 = count_dist_link(io.TextIOWrapper(response_test_1_2), io.TextIOWrapper(response_test_2_2))\n",
    "X_test = np.vstack((X_test_1, X_test_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/data_syntax/train_1_0.csv')\n",
    "response_2 = urllib.request.urlopen('https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/data_syntax/train_2_0.csv')\n",
    "X_train = count_dist_link(io.TextIOWrapper(response_1), io.TextIOWrapper(response_2))\n",
    "for i in range(1, 68):\n",
    "    response_1 = urllib.request.urlopen(f'https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/data_syntax/train_1_{i}.csv')\n",
    "    response_2 = urllib.request.urlopen(f'https://raw.githubusercontent.com/ulianakazak/Bigutochki/main/data_syntax/train_2_{i}.csv')\n",
    "    X = count_dist_link(io.TextIOWrapper(response_1), io.TextIOWrapper(response_2))\n",
    "    X_train = np.vstack((X_train, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import fbeta_score,make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('snli_1.0_train.jsonl', lines = True)\n",
    "test = pd.read_json('snli_1.0_test.jsonl', lines = True)\n",
    "val = pd.read_json('snli_1.0_dev.jsonl', lines = True)\n",
    "full = {'train': train, 'val':val, 'test': test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unsure_labels(data):\n",
    "    data = data.drop(index = data[data.gold_label == '-'].index)\n",
    "    return data\n",
    "\n",
    "\n",
    "for frame in full:\n",
    "    full[frame] = delete_unsure_labels(full[frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_unsure_labels_vec(X, data):\n",
    "    X = X[data.index]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full['train']\n",
    "val = full['val']\n",
    "test = full['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = delete_unsure_labels_vec(X_train, train)\n",
    "X_val = delete_unsure_labels_vec(X_val, val)\n",
    "X_test = delete_unsure_labels_vec(X_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train['gold_label'])\n",
    "y_val = np.array(val['gold_label'])\n",
    "y_test = np.array(test['gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.35201383 0.38617524 0.28150132]\n",
      "val: [0.83044389 0.12743774 0.01795841]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500, solver = 'saga')\n",
    "clf.fit(X_train, y_train)\n",
    "y_train_preds = clf.predict(X_train)\n",
    "f_train = fbeta_score(y_train, y_train_preds, beta=7, average=None,)\n",
    "y_val_preds = clf.predict(X_val)\n",
    "f_val = fbeta_score(y_val, y_val_preds, beta=7, average=None,)\n",
    "print(f'train: {f_train}')\n",
    "print(f'val: {f_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32906267, 0.33254567, 0.33654544])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500, solver = 'saga')\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=3, average='weighted')\n",
    "cross_val_score(clf, X_test, y_test, cv=3, scoring= ftwo_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.09069626 0.78048526 0.16737006]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500, solver = 'saga')\n",
    "clf.fit(X_test, y_test)\n",
    "y_train_preds = clf.predict(X_test)\n",
    "f_train = fbeta_score(y_test, y_train_preds, beta=7, average=None,)\n",
    "y_val_preds = clf.predict(X_val)\n",
    "f_val = fbeta_score(y_val, y_val_preds, beta=7, average=None,)\n",
    "print(f'train: {f_train}')\n",
    "print(f'val: {f_val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contradiction</th>\n",
       "      <td>0.334804</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.830444</td>\n",
       "      <td>3278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>0.308108</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.017958</td>\n",
       "      <td>3235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entailment</th>\n",
       "      <td>0.329144</td>\n",
       "      <td>0.125864</td>\n",
       "      <td>0.127438</td>\n",
       "      <td>3329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weighted*</th>\n",
       "      <td>0.326715</td>\n",
       "      <td>0.464028</td>\n",
       "      <td>0.451571</td>\n",
       "      <td>3280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision    recall    fscore  support\n",
       "contradiction   0.334804  0.856315  0.830444   3278.0\n",
       "neutral         0.308108  0.017620  0.017958   3235.0\n",
       "entailment      0.329144  0.125864  0.127438   3329.0\n",
       "Weighted*       0.326715  0.464028  0.451571   3280.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prfs = precision_recall_fscore_support(y_val, y_val_preds, beta=7, average=None, labels=['contradiction', 'neutral', 'entailment'])\n",
    "matrix_report = pd.DataFrame(prfs, columns = ['contradiction', 'neutral', 'entailment'], index = ['precision', 'recall', 'fscore', 'support'])\n",
    "matrix_report['Weighted*'] = 0.5 * matrix_report['contradiction'] +  0.25 * matrix_report['neutral'] +  0.25 * matrix_report['entailment']\n",
    "matrix_report.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
